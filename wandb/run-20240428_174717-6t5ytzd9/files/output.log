[32m2024-04-28 17:47:18.312[39m | [1mINFO    [22m | [36m__main__[39m:[36mmain[39m:[36m163[39m - [1mUsing dist with rank 0 (only rank 0 will log)
[32m2024-04-28 17:47:18.312[39m | [1mINFO    [22m | [36m__main__[39m:[36mmain[39m:[36m164[39m - [1m****************************************
[32m2024-04-28 17:47:18.312[39m | [1mINFO    [22m | [36m__main__[39m:[36mmain[39m:[36m165[39m - [1mStarting training with the arguments
[32m2024-04-28 17:47:18.313[39m | [1mINFO    [22m | [36m__main__[39m:[36mmain[39m:[36m167[39m - [1mmodel_config                   configs/llama_7b.json
[32m2024-04-28 17:47:18.313[39m | [1mINFO    [22m | [36m__main__[39m:[36mmain[39m:[36m167[39m - [1muse_hf_model                   False
[32m2024-04-28 17:47:18.313[39m | [1mINFO    [22m | [36m__main__[39m:[36mmain[39m:[36m167[39m - [1mcontinue_from                  None
[32m2024-04-28 17:47:18.313[39m | [1mINFO    [22m | [36m__main__[39m:[36mmain[39m:[36m167[39m - [1mbatch_size                     16
[32m2024-04-28 17:47:18.314[39m | [1mINFO    [22m | [36m__main__[39m:[36mmain[39m:[36m167[39m - [1mgradient_accumulation          32
[32m2024-04-28 17:47:18.314[39m | [1mINFO    [22m | [36m__main__[39m:[36mmain[39m:[36m167[39m - [1mtotal_batch_size               512
[32m2024-04-28 17:47:18.314[39m | [1mINFO    [22m | [36m__main__[39m:[36mmain[39m:[36m167[39m - [1mmax_length                     256
[32m2024-04-28 17:47:18.314[39m | [1mINFO    [22m | [36m__main__[39m:[36mmain[39m:[36m167[39m - [1moptimizer                      galore_adamw8bit_per_layer
[32m2024-04-28 17:47:18.315[39m | [1mINFO    [22m | [36m__main__[39m:[36mmain[39m:[36m167[39m - [1mlr                             0.005
[32m2024-04-28 17:47:18.315[39m | [1mINFO    [22m | [36m__main__[39m:[36mmain[39m:[36m167[39m - [1mscheduler                      cosine
[32m2024-04-28 17:47:18.315[39m | [1mINFO    [22m | [36m__main__[39m:[36mmain[39m:[36m167[39m - [1mmin_lr_ratio                   0.1
[32m2024-04-28 17:47:18.315[39m | [1mINFO    [22m | [36m__main__[39m:[36mmain[39m:[36m167[39m - [1mactivation_checkpointing       True
[32m2024-04-28 17:47:18.315[39m | [1mINFO    [22m | [36m__main__[39m:[36mmain[39m:[36m167[39m - [1mweight_decay                   0.0
[32m2024-04-28 17:47:18.315[39m | [1mINFO    [22m | [36m__main__[39m:[36mmain[39m:[36m167[39m - [1mwarmup_steps                   15000
[32m2024-04-28 17:47:18.316[39m | [1mINFO    [22m | [36m__main__[39m:[36mmain[39m:[36m167[39m - [1meval_every                     1000
[32m2024-04-28 17:47:18.316[39m | [1mINFO    [22m | [36m__main__[39m:[36mmain[39m:[36m167[39m - [1mnum_training_steps             150000
[32m2024-04-28 17:47:18.316[39m | [1mINFO    [22m | [36m__main__[39m:[36mmain[39m:[36m167[39m - [1mmax_train_tokens               None
[32m2024-04-28 17:47:18.317[39m | [1mINFO    [22m | [36m__main__[39m:[36mmain[39m:[36m167[39m - [1msave_every                     10000
[32m2024-04-28 17:47:18.317[39m | [1mINFO    [22m | [36m__main__[39m:[36mmain[39m:[36m167[39m - [1msave_dir                       checkpoints/llama_7b-2024-04-28-17-47-16
[32m2024-04-28 17:47:18.317[39m | [1mINFO    [22m | [36m__main__[39m:[36mmain[39m:[36m167[39m - [1mtags                           None
[32m2024-04-28 17:47:18.317[39m | [1mINFO    [22m | [36m__main__[39m:[36mmain[39m:[36m167[39m - [1mdtype                          bfloat16
[32m2024-04-28 17:47:18.317[39m | [1mINFO    [22m | [36m__main__[39m:[36mmain[39m:[36m167[39m - [1mworkers                        8
[32m2024-04-28 17:47:18.318[39m | [1mINFO    [22m | [36m__main__[39m:[36mmain[39m:[36m167[39m - [1mseed                           0
[32m2024-04-28 17:47:18.318[39m | [1mINFO    [22m | [36m__main__[39m:[36mmain[39m:[36m167[39m - [1mname                           test
[32m2024-04-28 17:47:18.318[39m | [1mINFO    [22m | [36m__main__[39m:[36mmain[39m:[36m167[39m - [1mgrad_clipping                  1.0
[32m2024-04-28 17:47:18.318[39m | [1mINFO    [22m | [36m__main__[39m:[36mmain[39m:[36m167[39m - [1mbeta1                          0.0
[32m2024-04-28 17:47:18.318[39m | [1mINFO    [22m | [36m__main__[39m:[36mmain[39m:[36m167[39m - [1mrank                           1024
[32m2024-04-28 17:47:18.318[39m | [1mINFO    [22m | [36m__main__[39m:[36mmain[39m:[36m167[39m - [1mupdate_proj_gap                500
[32m2024-04-28 17:47:18.319[39m | [1mINFO    [22m | [36m__main__[39m:[36mmain[39m:[36m167[39m - [1mgalore_scale                   0.25
[32m2024-04-28 17:47:18.319[39m | [1mINFO    [22m | [36m__main__[39m:[36mmain[39m:[36m167[39m - [1mproj_type                      std
[32m2024-04-28 17:47:18.319[39m | [1mINFO    [22m | [36m__main__[39m:[36mmain[39m:[36m167[39m - [1msingle_gpu                     True
[32m2024-04-28 17:47:18.319[39m | [1mINFO    [22m | [36m__main__[39m:[36mmain[39m:[36m168[39m - [1m****************************************
Downloading readme: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 41.1k/41.1k [00:00<00:00, 13.8MB/s]

Resolving data files: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1024/1024 [00:06<00:00, 162.55it/s]

Resolving data files: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1024/1024 [00:02<00:00, 497.58it/s]
[32m2024-04-28 17:47:37.262[39m | [1mINFO    [22m | [36m__main__[39m:[36mmain[39m:[36m174[39m - [1mShuffling data with seed 42
config.json: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1.21k/1.21k [00:00<00:00, 104kB/s]
spiece.model: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 792k/792k [00:00<00:00, 47.2MB/s]
tokenizer.json: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1.39M/1.39M [00:00<00:00, 28.1MB/s]
Traceback (most recent call last):
  File "torchrun_main.py", line 571, in <module>
    main(args)
  File "torchrun_main.py", line 239, in main
    model = model.to(device=device, dtype=torch.bfloat16)
  File "/home/ishida/GaLore/.env/lib/python3.8/site-packages/transformers/modeling_utils.py", line 1900, in to
    return super().to(*args, **kwargs)
  File "/home/ishida/GaLore/.env/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1145, in to
    return self._apply(convert)
  File "/home/ishida/GaLore/.env/lib/python3.8/site-packages/torch/nn/modules/module.py", line 797, in _apply
    module._apply(fn)
  File "/home/ishida/GaLore/.env/lib/python3.8/site-packages/torch/nn/modules/module.py", line 797, in _apply
    module._apply(fn)
  File "/home/ishida/GaLore/.env/lib/python3.8/site-packages/torch/nn/modules/module.py", line 797, in _apply
    module._apply(fn)
  [Previous line repeated 2 more times]
  File "/home/ishida/GaLore/.env/lib/python3.8/site-packages/torch/nn/modules/module.py", line 820, in _apply
    param_applied = fn(param)
  File "/home/ishida/GaLore/.env/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1143, in convert
    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 86.00 MiB (GPU 0; 11.77 GiB total capacity; 11.41 GiB already allocated; 57.06 MiB free; 11.42 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF